<DFS와 BFS 백트래킹>
  - 깊이 우선 탐색(DFS)
    : DFS는 가능한 모든 경로를 탐색한다. 따라서, 불필요할 것 같은 경로를 사전에
    차단하거나 하는 등의 행동이 없으므로 경우의 수를 줄이지 못함
    따라서 N! 가지늬 경우의 수를 가진 문제는 DFS로 처리가 불가능함
  
  - 너비 우선 탐색(BFS))
    : 

  -백트래킹(Backtracking)
    : 해를 찾아가는 도중, 지금의 경로가 해가 될 것 같지 않으면 그 경로를 더이상 가지
    않고, 되돌아간다. 코딩에서는 반복문의 횟수까지 줄일 수 있으므로 효율적이다.

    백트래킹은 N!의 경우의 수를 가진 문제에서 최악의 경우 지수함수 시간을 필요로 하므로
    처리가 불가능할 수 있음. 따라서 가지치기를 얼마나 잘하느냐에 따라 효율성이 결정됨.
    백트래킹은 모든 경우의 수 중에서 특정한 조건을 만족하는 경우만 살펴보는 것이다.

    주로 DFS 등으로 모든 경우의 수를 탐색하는 과정에서, 조건문 등을 걸어 답이 될 수 없는
    상황을 정의하고, 그러한 상황일 경우에는 탐색을 중지시킨 뒤 그 이전으로 돌아가서 다시 다른 경우를 탐색하게끔 구현할 수 있다.


<재귀>
  : 하나의 함수에서 자기 자신을 다시 호출해 작업을 수행하는 알고리즘
  ex)
    func1(n):
      if n == 0:
        return
      print(n )
      func1(n-1)
    
    func2(n):
      if n == 0:
        return 0
      return n+func2(n-1)

  - 재귀 함수의 조건
    1. 특정 입력에 대해서는 자기 자신을 호출하지 않고 종료되어야 한다.(base condition)
    2. 모든 입력은 base condition으로 수렴해야 한다.

  - 재귀의 대한 정보
    1. 함수의 인자로 어떤 것을 받고 어디까지 계산한 후 자기 자신에게 넘겨줄지 정해야 함
    2. 모든 재귀 함수는 반복문만으로 동일한 동작을 하는 함수를 만들 수 있음
    3. 재귀는 반복문으로 구현했을 때에 비해 코드가 간결하지만 메모리/시간에서 손해를 봄
    4. 한 함수가 자기 자신을 여러 번 호출하게 되면 비효율적일 수 있음
    5. 재귀함수가 자기 자신을 부를 때 스택 영역에 계속 누적이 됨
    
    1. 함수의 정의
    2. base condition
    3. 재귀 식
    


<유클리드 호제법>
  : 2개의 자연수 또는 정시의 최대공약수를 구하는 알고리즘
  호제법이라는 말은 두 수가 서로 상대방 수를 나누어서 결국 원하는 수를 얻는 알고리즘

  2개의 자연수(또는 정식) a, b에 대해서 a를 b로 나눈 나머지를 r이라 하면(단, a>b), 
  a와 b의 최대공약수는 b와 r의 최대공약수와 같다.
  
  ex)
    def gcd(a, b):
      while b > 0:
        a, b = b, a % b
      return a

  (최대공약수)
    a * b = GGx*y
    a * b / G = GGx*y / G (양변에 최소 공약수를 나누어 줌)
    a * b / G = Gxy(최소공배수)
    최소공배수 = a * b / G

    ex)
      def lcm(a, b):
        return a * b // gcd(a, b)


<정렬 알고리즘>
  : 데이터를 특정한 기준에 따라 순서대로 나열하는 것


  1. 버블 정렬
    : 인접한 두 수를 비교하며 정렬해나간는 방법으로 O(n^2)의 느린 성능을 가지고 있다.

      1. 앞에서부터 시작하여 큰 수를 뒤로 보내 뒤가 가장 큰 값을 가지도록 완성해가는 방법
      2. 뒤에서부터 반복하여 앞의 작은 값부터 정렬을 완성해 나가는 방법

      ex)
        array = [9,8,7,6,5,4,3,2,1]

        def bubble_sort(array):
            n = len(array)
            for i in range(n - 1):
                for j in range(n - i - 1):
                    if array[j] > array[j + 1]:
                        array[j], array[j + 1] = array[j + 1], array[j]
                print(array)
        print("before: ",array)
        bubble_sort(array)
        print("after:", array)
  

  2. 선택 정렬
    : 처리되지 않은 데이터 중에서 가장 작은 데이터를 선택해 맨 앞에 있는 데이터와 바꾸는 것을 반복한다. 
      선택 정렬의 시간복잡도 : O(N^2)

      ex)
        array = [8,4,6,2,9,1,3,7,5]

        def selection_sort(array):
          n = len(array)
          for i in range(n):
            min_index = i
            for j in range(i + 1, n):
              if array[j] < array[min_index]:
                min_index = j
            array[i], array[min_index] =  array[min_index], array[i]
            print(array[:i+1])

        print("before: ",array)
        selection_sort(array)
        print("after:", array)


  3.삽입 정렬
    : 처리되지 않은 데이터를 하나씩 골라 적절한 위치에 삽입한다.
      (선택 정렬에 비해 구현 난이도가 높지만, 일반적으로 더 효율적이다.)

      삽입 정렬의 시간복잡도 : O(N^2) 단 최상의 경우 O(N)이 됨

      ex)
        array = [8,4,6,2,9,1,3,7,5]

        def insertion_sort(array):
          n = len(array)
          for i in range(1, n):
            for j in range(i, 0, - 1):
              if array[j - 1] > array[j]:
                array[j - 1], array[j] = array[j], array[j - 1]
            print(array[:i+1])

        print("before: ",array)
        insertion_sort(array)
        print("after:", array)


  4. 병합 정렬
    : 분할 정복과 재귀를 이용한 알고리즘으로 O(NlogN)의 속도이다.
      반으로 쪼개고 다시 합치는 과정에서 그룹을 만들어 정렬하게 되며 이 과정에서
      2n개의 공간이 필요하다.
    
    ex)
      array = [8,4,6,2,9,1,3,7,5]

      def merge_sort(array):
        if len(array) < 2:
          return array
        mid = len(array) // 2
        low_arr = merge_sort(array[:mid])
        high_arr = merge_sort(array[mid:])

        merged_arr = []
        l = h = 0
        while l < len(low_arr) and h < len(high_arr):
          if low_arr[l] < high_arr[h]:
            merged_arr.append(low_arr[l])
            l += 1
          else:
            merged_arr.append(high_arr[h])
            h += 1
        merged_arr += low_arr[l:]
        merged_arr += high_arr[h:]
        print(merged_arr)
        return merged_arr

      print("before: ",array)
      array = merge_sort(array)
      print("after:", array)

  5. 계수 정렬
    : 계수 정렬은 비교 정렬이 아니며, 특정한 조건(데이터의 크기 범위가 제한되어 정수
    형태로 표현할 수 있을때)이 부합할때만 사용가능하지만 매우 빠르게 동작한다.

    데이터의 개수가 N, 데이터(양수)중 최댓값이 K일 때 최악의 경우에도 수행시간
    O(N + K)를 보장한다.

    ex)
      array = [7, 5, 9, 0, 3, 1, 6, 2, 9, 1, 4, 8, 0, 5, 2]
      count = [0] * (max(array) + 1)

      for i in range(len(array)):
        count[array[i]] += 1 # 각 데이터에 해당하는 인덱스의 값 증가
        
      for i in range(len(count)): # 리스트에 기록된 정렬 정보 확인
        for j in range(count[i]):
          print(i, end=' ') # 띄어쓰기를 구분으로 등장한 횟수만큼 인덱스 출력



  6. 퀵 정렬
    : 기준 데이터를 설정하고 그 기준보다 큰 데이터와 작은 데이터의 위치를 바꾸는 방법.
    
    일반적인 상황에서 가장 많이 사용됨
    병합 정렬과 함께 대부분의 프로그래밍 언어의 정렬 라이브러리의 근간이 됨
    가장 기본적인 퀵 정렬은 첫 번째 데이터를 기준 데이터로 설정

    퀵 정렬의 시간복잡도 : O(NlogN) 단 최악의 경우 O(N^2)의 시간복잡도를 갖는다.

  5. 계수 정렬


<그리디 알고리즘 (탐욕법)>
  : 그리디 알고리즘은 현재 상황에서 지금 당장 좋은 것만 고르는 방법

  코딩 테스트에서의 대부분의 그리디 문제는 탐욕법으로 얻은 해가 최적의 해가 되는 상황에서, 이 를 추론할 수 있어야 풀리도록 출제된다.

  검증 종류가 K개라고 할때, 소스코드의 시간 복잡도는 O(K)이다.


<다이나믹 프로그래밍>
  : 메모리 공간을 약간 더 사용해서 연산 속도를 비약적으로 증가시키는 방법이다.

  1. 큰 문제를 작은 문제로 나눌 수 있다.
  2. 작은 문제에서 구한 정답은 그것을 포함하는 큰 문제에서도 동일하다.
  이 두가지 조건을 만족할때 다이나믹 프로그래밍을 사용할 수 있다.

  다이나믹 프로그래밍의 포인트는 한 번 결과를 수행한 것을 메모리에 저장해 놓고 다음에
  똑같은 결과가 필요하면 다시 연산하지 않고 메모리에 저장된 그 값을 가져와 쓰는 것이다.
  Top-Down : 메모제이션(캐싱) 기법, Bottom-Up : DP 테이블
  
  ex)
    d = [0] * 50

    def fibo(x):
        if x == 1 or x == 2:
            return 1
        if d[x] != 0:
            return d[x]
        d[x] = fibo(x-1) + fibo(x-2)
        return d[x]
  이 처럼 재귀함수를 사용해 구현하는 다이나믹 프로그래밍 방법은 메모제이션 기법을 활요한
  Top-Down 방식이라고 한다. 즉 큰 문제를 해결하기 위해 작은 문제를 호출하는것.

  반면에 재귀함수를 사용하지 않고 단순반복문을 사용해 다이나믹 프로그래밍을 구현할 수 있다.
  ex)
    d = [0] * 100

    d[1] = 1 # 첫 번째 항
    d[2] = 1 # 두 번째 항
    N = 99   # 피보나치 수열의 99번째 숫자는?

    for i in range(3, N+1):
        d[i] = d[i-1] + d[i-2]
    print(d[N])
  위와 같은 방식은 작은 문제부터 차근차근 답을 도출해서 큰 문제를 해결한다고 하여
  Bottom-Up 방식이라고 한다.

  Top-Down 방식의 메모제이션 기법은 사전 자료형을 이용할 수 있는데 이는 수열처럼 연속적이지 않은 자료가 주어질때 유용하다. (일부의 결과만 필요할 경우)

  다이나믹 프로그래밍은 단순 반복문을 활요하는 Bottom-Up 방식으로 해결하라고 권장됨
  재귀함수를 이용하는 Top-Down 방식을 사용하다가 횟수 제한에 걸릴 수 있기 때문


<에라토스테네스의 체> (정수론)
  : 고대 그리스의 수학자 에라토스테네스가 만들어낸 소수를 찾는 방법.
  f(x)= (x) / 1P(x) 의 수열을 표로 시각화한 것

  임의의 자연수 n에 대해 그 이하의 소수를 찾는 가장 간단하고 빠른 방법. O(N)

  예를 들어 1~100까지 숫자중 소수를 찾는다 한다.
  1. 1부터 100까지 숫자를 쭉 쓴다.
  2. 일단 소수도, 합성수도 아닌 유일한 자연수 1(기초수)을 제거한다.
  3. 2를 제외한 2의 배수를 제거한다.
  4. 3을 제외한 3의 배수를 제거한다.
  5. 5를 제외한 5의 배수를 제거한다.
  6. 7을 제외한 7의 배수를 제거한다.
  이렇게 남은 수들이 100이하의 소수이다.

  에라토스테네스의 체는 '특정 범위 내의 소수'를 판정하는 데에만 효율적이며, 만약
  주어진 수 하나가 소수인가? 를 묻는 상황이면 소수 판정법이 더 빠르다.

  ex)
    def prime_list(n):
      # 에라토스테네스의 체 초기화: n개 요소에 True 설정(소수로 간주)
      sieve = [True] * n

      # n의 최대 약수가 sqrt(n) 이하이므로 i=sqrt(n)까지 검사
      m = int(n ** 0.5)
      for i in range(2, m + 1):
          if sieve[i] == True:           # i가 소수인 경우
              for j in range(i+i, n, i): # i이후 i의 배수들을 False 판정
                  sieve[j] = False

      # 소수 목록 산출
      return [i for i in range(2, n) if sieve[i] == True]

<소수 판별법> (Primality Test)
  : 소수는 1과 자기 자신으로만 나누어 떨어지는 자연수를 뜻한다.
    합성수는 2 이상의 자연수 중 나누어 떨어지는 수가 2개 이상인 경우에 해당한다.

  (약수 세기)
  1. 1에서 n까지를 순회하며 n과 나누어 떨어지는지 하나하나 확인해 보는것 O(N)
  2. 자연수 a가 n의 약수일때 n/a 또한 n의 약수가 되는점을 이용해 n^(1/2)의 순회를
     이용해 약수를 센다. O(n^(1/2))
  
  (소수 판별법)
    : [2, n]의 범위에 약수가 존재한느지 확인함으로써 소수 판별법을 구현할 수 있음
    O(n^(1/2))

    ex)
      def primality(n):
        i = 2
        while i*i <= n:
          if n % i == 0:
            return False
          i += 1
        return True